{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, Dense, Flatten, Conv2D\n",
    "from keras import backend as K\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=80\n",
    "img_width=80\n",
    "channel=3\n",
    "X_train=np.empty([8005, img_height, img_width, channel], np.int32)\n",
    "X_test=np.empty([2023, img_height, img_width, channel], np.int32)\n",
    "y_train=np.full([8005,], fill_value=5)\n",
    "y_test=np.full([2023,], fill_value=6)\n",
    "i = 0\n",
    "# cat = 0 , dog =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in glob.iglob('training_set/cats/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_train[i] = 0\n",
    "    X_train[i] = img\n",
    "    i = i + 1\n",
    "    \n",
    "for filepath in glob.iglob('training_set/dogs/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_train[i] = 1\n",
    "    X_train[i] = img\n",
    "    i = i + 1    \n",
    "    \n",
    "i=0    \n",
    "    \n",
    "for filepath in glob.iglob('test_set/cats/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_test[i] = 0\n",
    "    X_test[i] = img\n",
    "    i = i + 1\n",
    "    \n",
    "for filepath in glob.iglob('test_set/dogs/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_test[i] = 1\n",
    "    X_test[i] = img\n",
    "    i = i + 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test  = keras.utils.to_categorical(y_test, 2)\n",
    "input_shape=(img_height, img_width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2,2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8005 samples, validate on 2023 samples\n",
      "Epoch 1/10\n",
      "8005/8005 [==============================] - 30s 4ms/step - loss: 0.6708 - accuracy: 0.5843 - val_loss: 0.6509 - val_accuracy: 0.6110\n",
      "Epoch 2/10\n",
      "8005/8005 [==============================] - 29s 4ms/step - loss: 0.6053 - accuracy: 0.6701 - val_loss: 0.5783 - val_accuracy: 0.7098\n",
      "Epoch 3/10\n",
      "8005/8005 [==============================] - 31s 4ms/step - loss: 0.5484 - accuracy: 0.7269 - val_loss: 0.5391 - val_accuracy: 0.7459\n",
      "Epoch 4/10\n",
      "8005/8005 [==============================] - 35s 4ms/step - loss: 0.5110 - accuracy: 0.7567 - val_loss: 0.5207 - val_accuracy: 0.7563\n",
      "Epoch 5/10\n",
      "8005/8005 [==============================] - 36s 4ms/step - loss: 0.4777 - accuracy: 0.7766 - val_loss: 0.5278 - val_accuracy: 0.7464\n",
      "Epoch 6/10\n",
      "8005/8005 [==============================] - 35s 4ms/step - loss: 0.4656 - accuracy: 0.7791 - val_loss: 0.5975 - val_accuracy: 0.7177\n",
      "Epoch 7/10\n",
      "8005/8005 [==============================] - 35s 4ms/step - loss: 0.4647 - accuracy: 0.7816 - val_loss: 0.4899 - val_accuracy: 0.7781\n",
      "Epoch 8/10\n",
      "8005/8005 [==============================] - 35s 4ms/step - loss: 0.4382 - accuracy: 0.7949 - val_loss: 0.4830 - val_accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "8005/8005 [==============================] - 35s 4ms/step - loss: 0.4146 - accuracy: 0.8147 - val_loss: 0.4806 - val_accuracy: 0.7761\n",
      "Epoch 10/10\n",
      "8005/8005 [==============================] - 36s 4ms/step - loss: 0.4009 - accuracy: 0.8182 - val_loss: 0.4871 - val_accuracy: 0.7721\n",
      "2023/2023 [==============================] - 2s 1ms/step\n",
      "Loss: 0.4870687346910994\n",
      "Accuracy: 0.7721205949783325\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cat_dog.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved an accuracy of 77%. Data augmentation can probably be used to improve accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
