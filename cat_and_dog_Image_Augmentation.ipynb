{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, Dense, Flatten, Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=80\n",
    "img_width=80\n",
    "channel=3\n",
    "X_train=np.empty([8005, img_height, img_width, channel], np.int32)\n",
    "X_test=np.empty([2023, img_height, img_width, channel], np.int32)\n",
    "y_train=np.full([8005,], fill_value=5)\n",
    "y_test=np.full([2023,], fill_value=6)\n",
    "i = 0\n",
    "# cat = 0 , dog =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in glob.iglob('training_set/cats/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_train[i] = 0\n",
    "    X_train[i] = img\n",
    "    i = i + 1\n",
    "    \n",
    "for filepath in glob.iglob('training_set/dogs/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_train[i] = 1\n",
    "    X_train[i] = img\n",
    "    i = i + 1    \n",
    "    \n",
    "i=0    \n",
    "    \n",
    "for filepath in glob.iglob('test_set/cats/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_test[i] = 0\n",
    "    X_test[i] = img\n",
    "    i = i + 1\n",
    "    \n",
    "for filepath in glob.iglob('test_set/dogs/*.jpg'):\n",
    "    img=Image.open(filepath)\n",
    "    img=img.resize((img_height,img_width), Image.ANTIALIAS)\n",
    "    img=np.array(img)\n",
    "    y_test[i] = 1\n",
    "    X_test[i] = img\n",
    "    i = i + 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test  = keras.utils.to_categorical(y_test, 2)\n",
    "input_shape=(img_height, img_width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_aug = ImageDataGenerator(\n",
    "                rotation_range=15,\n",
    "                width_shift_range=0.15,\n",
    "                height_shift_range=0.15,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "img_aug.fit(X_train, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2,2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/250 [==============================] - 34s 135ms/step - loss: 0.6552 - accuracy: 0.6074\n",
      "Epoch 2/50\n",
      "251/250 [==============================] - 34s 137ms/step - loss: 0.5956 - accuracy: 0.6803\n",
      "Epoch 3/50\n",
      "251/250 [==============================] - 30s 118ms/step - loss: 0.5688 - accuracy: 0.7044\n",
      "Epoch 4/50\n",
      "251/250 [==============================] - 29s 117ms/step - loss: 0.5546 - accuracy: 0.7225\n",
      "Epoch 5/50\n",
      "251/250 [==============================] - 29s 116ms/step - loss: 0.5256 - accuracy: 0.7445\n",
      "Epoch 6/50\n",
      "251/250 [==============================] - 27s 110ms/step - loss: 0.5207 - accuracy: 0.7458\n",
      "Epoch 7/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.5129 - accuracy: 0.7538\n",
      "Epoch 8/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.5076 - accuracy: 0.7503\n",
      "Epoch 9/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.4939 - accuracy: 0.7598\n",
      "Epoch 10/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4906 - accuracy: 0.7645\n",
      "Epoch 11/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4761 - accuracy: 0.7719\n",
      "Epoch 12/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4705 - accuracy: 0.7780\n",
      "Epoch 13/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4645 - accuracy: 0.7828\n",
      "Epoch 14/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4506 - accuracy: 0.7930\n",
      "Epoch 15/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4591 - accuracy: 0.7866\n",
      "Epoch 16/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4444 - accuracy: 0.7959\n",
      "Epoch 17/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.4502 - accuracy: 0.7913\n",
      "Epoch 18/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.4468 - accuracy: 0.7950\n",
      "Epoch 19/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.4391 - accuracy: 0.7984\n",
      "Epoch 20/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.4299 - accuracy: 0.8056\n",
      "Epoch 21/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4326 - accuracy: 0.8062\n",
      "Epoch 22/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4239 - accuracy: 0.8045\n",
      "Epoch 23/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4164 - accuracy: 0.8102\n",
      "Epoch 24/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4169 - accuracy: 0.8072\n",
      "Epoch 25/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4176 - accuracy: 0.8061\n",
      "Epoch 26/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4163 - accuracy: 0.8051\n",
      "Epoch 27/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4054 - accuracy: 0.8137\n",
      "Epoch 28/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4193 - accuracy: 0.8096\n",
      "Epoch 29/50\n",
      "251/250 [==============================] - 28s 111ms/step - loss: 0.4095 - accuracy: 0.8149\n",
      "Epoch 30/50\n",
      "251/250 [==============================] - 28s 110ms/step - loss: 0.4074 - accuracy: 0.8137\n",
      "Epoch 31/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.4015 - accuracy: 0.8177\n",
      "Epoch 32/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3961 - accuracy: 0.8194\n",
      "Epoch 33/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3952 - accuracy: 0.8244\n",
      "Epoch 34/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3963 - accuracy: 0.8222\n",
      "Epoch 35/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3924 - accuracy: 0.8209\n",
      "Epoch 36/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3917 - accuracy: 0.8192\n",
      "Epoch 37/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3948 - accuracy: 0.8199\n",
      "Epoch 38/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3814 - accuracy: 0.8296\n",
      "Epoch 39/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3820 - accuracy: 0.8239\n",
      "Epoch 40/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3831 - accuracy: 0.8306\n",
      "Epoch 41/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3807 - accuracy: 0.8285\n",
      "Epoch 42/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3924 - accuracy: 0.8197\n",
      "Epoch 43/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3726 - accuracy: 0.8326\n",
      "Epoch 44/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3753 - accuracy: 0.8337\n",
      "Epoch 45/50\n",
      "251/250 [==============================] - 27s 110ms/step - loss: 0.3709 - accuracy: 0.8364\n",
      "Epoch 46/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3783 - accuracy: 0.8264\n",
      "Epoch 47/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3728 - accuracy: 0.8269\n",
      "Epoch 48/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3730 - accuracy: 0.8345\n",
      "Epoch 49/50\n",
      "251/250 [==============================] - 27s 108ms/step - loss: 0.3519 - accuracy: 0.8394\n",
      "Epoch 50/50\n",
      "251/250 [==============================] - 27s 109ms/step - loss: 0.3618 - accuracy: 0.8377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f35e0338810>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(img_aug.flow(X_train, y_train, batch_size=32), steps_per_epoch=len(X_train) / 32, verbose=1, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/2023 [==============================] - 2s 902us/step\n",
      "Loss: 0.37633990856956506\n",
      "Accuracy: 0.8433020114898682\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test, y_test)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('cat_dog.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved an accuracy of 84.33%. This is an improvement of almost 7% over my previous model which did not use image augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
